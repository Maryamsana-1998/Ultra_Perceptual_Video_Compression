{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29bd70f-fefa-485e-936f-ab477630ecc6",
   "metadata": {},
   "source": [
    "# Benchmarking Code and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eae4a96-06d0-4bcd-8cd6-59b585c5b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/maryam.sana/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "/data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `FrechetInceptionDistance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/maryam.sana/anaconda3/envs/unicontrol/lib/python3.8/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import test_utils\n",
    " # replace with actual import if needed\n",
    "importlib.reload(test_utils)\n",
    "from test_utils import calculate_metrics_batch \n",
    "\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional,Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8c9ca-6d4c-49ab-97b2-3c06196855d2",
   "metadata": {},
   "source": [
    "## HEVC and H264 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c7eda-1665-4606-a274-bf6c71b7d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Your evaluation function (should be defined elsewhere) ===\n",
    "# def calculate_metrics_batch(orig_images, pred_images) -> Dict[str, float]:\n",
    "#     return {\"PSNR\": ..., \"MS-SSIM\": ..., \"LPIPS\": ..., \"FID\": ..., \"FVD\": ...}\n",
    "\n",
    "# === Config ===\n",
    "BASE_PRED = Path(\"./test_codec\")\n",
    "BASE_ORIG = Path(\"../data/UVG_test_data\")\n",
    "OUTPUT_FILE = \"metrics_results_h265.txt\"\n",
    "\n",
    "# === Core Functions ===\n",
    "\n",
    "def load_images_from_folder(folder: Path) -> list:\n",
    "    return [Image.open(f) for f in sorted(folder.glob(\"*.png\"))]\n",
    "\n",
    "def evaluate_crf(video: str, crf_dir: Path, orig_frames: list) -> list[str]:\n",
    "    pred_frames = load_images_from_folder(crf_dir)\n",
    "    min_len = min(len(orig_frames), len(pred_frames))\n",
    "    if min_len == 0:\n",
    "        return []\n",
    "    metrics = calculate_metrics_batch(orig_frames[:min_len], pred_frames[:min_len])\n",
    "    return [\n",
    "        f\"{video},{crf_dir.name},\"\n",
    "        f\"{metrics['PSNR']:.4f},{metrics['MS-SSIM']:.4f},\"\n",
    "        f\"{metrics['LPIPS']:.4f},{metrics['FID']:.4f},{metrics['FVD']:.4f}\"\n",
    "    ]\n",
    "\n",
    "def evaluate_video(video_dir: Path, orig_base: Path) -> list[str]:\n",
    "    video_name = video_dir.name\n",
    "    crf_root = video_dir / \"h265\"\n",
    "    orig_path = orig_base / video_name / \"1080p\"\n",
    "\n",
    "    if not crf_root.is_dir() or not orig_path.is_dir():\n",
    "        return []\n",
    "\n",
    "    orig_frames = load_images_from_folder(orig_path)\n",
    "    results = []\n",
    "\n",
    "    for crf_dir in tqdm(sorted(crf_root.iterdir()), desc=f\"{video_name} CRFs\", leave=False):\n",
    "        if crf_dir.is_dir():\n",
    "            row = evaluate_crf(video_name, crf_dir, orig_frames)\n",
    "            if row:\n",
    "                results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# === Main ===\n",
    "\n",
    "def main():\n",
    "    all_results = []\n",
    "\n",
    "    for video_dir in tqdm(sorted(BASE_PRED.iterdir()), desc=\"Videos\"):\n",
    "        if video_dir.is_dir():\n",
    "            all_results.extend(evaluate_video(video_dir, BASE_ORIG))\n",
    "\n",
    "    # Save to file\n",
    "    with open(OUTPUT_FILE, \"w\") as f:\n",
    "        f.write(\"Video,CRF,PSNR,MS-SSIM,LPIPS,FID,FVD\\n\")\n",
    "        for line in all_results:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    print(f\"\\n✅ Metrics saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690680-d040-4ba4-8a1d-aa0a043f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_bpp(df_grouped: pd.DataFrame, bpp_df: pd.DataFrame, codec_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Attach BPP column to a grouped codec DataFrame based on codec name.\"\"\"\n",
    "    bpp_values = bpp_df.loc[bpp_df['Codec'] == codec_name, 'BPP'].values\n",
    "    df_grouped = df_grouped.copy()\n",
    "    df_grouped['BPP'] = bpp_values\n",
    "    return df_grouped\n",
    "\n",
    "def save_codec_metrics(df_grouped: pd.DataFrame, codec_name: str, out_dir: str = \"benchmark\"):\n",
    "    \"\"\"Save codec metrics with BPP to a CSV file.\"\"\"\n",
    "    filename = f\"{out_dir}/{codec_name}_gop8_benchmarking.csv\"\n",
    "    df_grouped.to_csv(filename, index=False)\n",
    "    print(f\"✅ Saved: {filename}\")\n",
    "\n",
    "# === Usage ===\n",
    "h264_grouped = attach_bpp(h264_grouped, bpp_df, \"h264\")\n",
    "h265_grouped = attach_bpp(h265_grouped, bpp_df, \"h265\")\n",
    "\n",
    "# Save results\n",
    "save_codec_metrics(h264_grouped, \"h264\")\n",
    "save_codec_metrics(h265_grouped, \"h265\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66598374-4f5d-4db6-912e-ff3983539d98",
   "metadata": {},
   "source": [
    "## UniControl Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c58b1ad-aebb-4b78-b385-19ca360389b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos:   0%|                                                                                    | 0/7 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video_path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mevaluate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgops\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# DataFrame\u001b[39;00m\n\u001b[1;32m     55\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m, in \u001b[0;36mevaluate_video\u001b[0;34m(video, orig_root, pred_root, gops)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m pred_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mlen\u001b[39m(orig_images) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(pred_images)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     28\u001b[0m     min_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(orig_images), \u001b[38;5;28mlen\u001b[39m(pred_images))\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36mload_images\u001b[0;34m(img_dir, size)\u001b[0m\n\u001b[1;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(f)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size:\n\u001b[0;32m---> 11\u001b[0m     images \u001b[38;5;241m=\u001b[39m [img\u001b[38;5;241m.\u001b[39mresize(size, Image\u001b[38;5;241m.\u001b[39mLANCZOS) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(f)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size:\n\u001b[0;32m---> 11\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "File \u001b[0;32m/data/maryam.sana/anaconda3/envs/unicontrolnew/lib/python3.8/site-packages/PIL/Image.py:2328\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2317\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2318\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2320\u001b[0m         )\n\u001b[1;32m   2321\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2322\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2323\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2324\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2325\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2326\u001b[0m         )\n\u001b[0;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_images(img_dir: Path, size=None) -> list:\n",
    "    files = sorted([f for f in img_dir.iterdir() if f.suffix == '.png'])\n",
    "    images = [Image.open(f).convert(\"RGB\") for f in files]\n",
    "    if size:\n",
    "        images = [img.resize(size, Image.LANCZOS) for img in images]\n",
    "    return images\n",
    "\n",
    "def evaluate_video(video: str, orig_root: Path, pred_root: Path, gops: list) -> list:\n",
    "    orig_dir = orig_root / video / \"1080p\"\n",
    "    orig_images = load_images(orig_dir)\n",
    "    results = []\n",
    "\n",
    "    for gop in gops:\n",
    "        pred_dir = pred_root / video / gop / \"1080p\"\n",
    "        if not pred_dir.exists():\n",
    "            print(f\"⚠️ Missing: {pred_dir}\")\n",
    "            continue\n",
    "\n",
    "        pred_images = load_images(pred_dir, size=orig_images[0].size)[:-1]\n",
    "\n",
    "        if abs(len(orig_images) - len(pred_images)) == 1:\n",
    "            min_len = min(len(orig_images), len(pred_images))\n",
    "            orig_images = orig_images[:min_len]\n",
    "            pred_images = pred_images[:min_len]\n",
    "            print(f\"⚠️ Trimmed: {video}-{gop} → {min_len} frames\")\n",
    "        elif len(orig_images) != len(pred_images):\n",
    "            print(f\"❌ Skipped: {video}-{gop} ({len(orig_images)} vs {len(pred_images)})\")\n",
    "            continue\n",
    "\n",
    "        metrics = calculate_metrics_batch(orig_images, pred_images)\n",
    "        metrics.update(video=video, gop=gop)\n",
    "        results.append(metrics)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main\n",
    "orig_root = Path(\"../data/UVG\")\n",
    "pred_root = Path(\"./unicontrol_codec\")\n",
    "gops = [\"gop4\", \"gop8\", \"gop16\"]\n",
    "\n",
    "all_results = []\n",
    "for video in tqdm(sorted(os.listdir(orig_root)), desc=\"Processing Videos\"):\n",
    "    video_path = orig_root / video\n",
    "    if not video_path.is_dir():\n",
    "        continue\n",
    "    all_results.extend(evaluate_video(video, orig_root, pred_root, gops))\n",
    "\n",
    "# DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "df_video = df[[\"video\", \"gop\"] + [col for col in df.columns if col not in [\"video\", \"gop\"]]]  # reorder\n",
    "\n",
    "print(\"\\nPer-GOP Averages:\")\n",
    "print(df_video.groupby(\"gop\").mean(numeric_only=True))\n",
    "\n",
    "# Save\n",
    "df_video.to_csv(\"unicontrol_1080_flow_video.csv\", index=False)\n",
    "df_video.groupby(\"gop\").mean(numeric_only=True).to_csv(\"unicontrol_1080_flow_UVG.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbe149-88bd-427f-939b-4116ee735dc4",
   "metadata": {},
   "source": [
    "## UniControl Bpp Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4aa3f7e-5114-4ba6-94c4-f1d49496f85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       video    gop  intra_kb      flow_kb\n",
      "0     Beauty   gop4    545.61  1385.085938\n",
      "1     Beauty   gop8    273.63  1615.933594\n",
      "2     Beauty  gop16    138.91  1731.357422\n",
      "3  Bosphorus   gop4    938.48  2262.023438\n",
      "4  Bosphorus   gop8    487.74  2639.027344\n"
     ]
    }
   ],
   "source": [
    "# ---------- generic helpers --------------------------------------------------\n",
    "KB = 1024.0\n",
    "TOTAL_FRAMES = 97          # change if your dataset differs\n",
    "GOPS          = (4, 8, 16) # gops you care about\n",
    "\n",
    "def read_frame_sizes(report_path: Path) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Return {frame_index: size_kb} from one compression_report.txt.\n",
    "    Accepts either of the two formats you showed.\n",
    "\n",
    "      frame_0000.png → 74.69 KB\n",
    "      - frame_0000.png: 74.69 KB\n",
    "    \"\"\"\n",
    "    if not report_path.is_file():\n",
    "        raise FileNotFoundError(report_path)\n",
    "\n",
    "    pat_arrow = re.compile(r\"frame_(\\d{4})\\.png\\s*→\\s*([\\d.]+)\\s*KB\")\n",
    "    pat_colon = re.compile(r\"frame_(\\d{4})\\.png:\\s*([\\d.]+)\\s*KB\")\n",
    "\n",
    "    sizes = {}\n",
    "    for line in report_path.read_text().splitlines():\n",
    "        m = pat_arrow.search(line) or pat_colon.search(line)\n",
    "        if m:\n",
    "            idx, kb = m.groups()\n",
    "            sizes[int(idx)] = float(kb)\n",
    "    return sizes\n",
    "\n",
    "\n",
    "def intra_storage_kb(frame_sizes: Dict[int, float],\n",
    "                     gop: int,\n",
    "                     total_frames: int = TOTAL_FRAMES) -> float:\n",
    "    \"\"\"Sum sizes of every gop-th frame starting from 0.\"\"\"\n",
    "    return sum(frame_sizes.get(i, 0.0) for i in range(0, total_frames, gop))\n",
    "\n",
    "\n",
    "# ---------- optical-flow helpers ---------------------------------------------\n",
    "def first_bin_size_kb(flow_dir: Path) -> Optional[float]:\n",
    "    \"\"\"Return size (KB) of first .bin inside a folder, or None.\"\"\"\n",
    "    for f in flow_dir.iterdir():\n",
    "        if f.suffix == \".bin\":\n",
    "            return f.stat().st_size / KB\n",
    "    return None\n",
    "\n",
    "\n",
    "def flow_storage_kb(video_1080p: Path, gop: int,\n",
    "                    fallback_size_kb: Optional[float]) -> float:\n",
    "    \"\"\"\n",
    "    Estimate total flow storage as  (#png) × (size of one .bin).\n",
    "\n",
    "    If this GOP has no .bin, uses fallback_size_kb (often GOP-8 size).\n",
    "    \"\"\"\n",
    "    flow_dir = video_1080p / f\"optical_flow_gop_{gop}\"\n",
    "    if not flow_dir.is_dir():\n",
    "        return 0.0\n",
    "\n",
    "    size_kb = first_bin_size_kb(flow_dir) or fallback_size_kb or 0.0\n",
    "    num_png = len([p for p in flow_dir.iterdir() if p.suffix == \".png\"])\n",
    "    return size_kb * num_png\n",
    "\n",
    "\n",
    "# ---------- one-video processing ---------------------------------------------\n",
    "def process_one_video(video_dir: Path,\n",
    "                      decoded_sub = \"decoded_q4\",\n",
    "                      gops       = GOPS) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns a list of rows (one per gop) with keys:\n",
    "      video • gop • intra_kb • flow_kb\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # ---- intra-frame sizes ---------------------------------------------------\n",
    "    report = video_dir / \"1080p\" / decoded_sub / \"compression_report.txt\"\n",
    "    try:\n",
    "        f_sizes = read_frame_sizes(report)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  missing report: {report}\")\n",
    "        return rows\n",
    "\n",
    "    # ---- optical-flow bin fallback (prefer gop-8) ---------------------------\n",
    "    g8_dir = video_dir / \"1080p\" / \"optical_flow_gop_8\"\n",
    "    fallback_kb = first_bin_size_kb(g8_dir)\n",
    "\n",
    "    # ---- per-GOP aggregation -------------------------------------------------\n",
    "    for g in gops:\n",
    "        rows.append(\n",
    "            dict(\n",
    "                video=video_dir.name,\n",
    "                gop=f\"gop{g}\",\n",
    "                intra_kb=intra_storage_kb(f_sizes, g),\n",
    "                flow_kb=flow_storage_kb(video_dir / \"1080p\", g, fallback_kb),\n",
    "            )\n",
    "        )\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ---------- dataset-wide driver ----------------------------------------------\n",
    "def build_storage_dataframe(base_dir: Union[str, Path],\n",
    "                            decoded_sub = \"decoded_q4\",\n",
    "                            gops       = GOPS) -> pd.DataFrame:\n",
    "    records = []\n",
    "    base = Path(base_dir)\n",
    "    for video_dir in sorted(base.iterdir()):\n",
    "        if video_dir.is_dir():\n",
    "            records.extend(process_one_video(video_dir,\n",
    "                                             decoded_sub=decoded_sub,\n",
    "                                             gops=gops))\n",
    "    df = pd.DataFrame(records)\n",
    "    # Optional pivot to wide format (one row per video)\n",
    "    #   df = df.pivot(index=\"video\", columns=\"gop\", values=[\"intra_kb\",\"flow_kb\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------- run ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = build_storage_dataframe(\"../data/UVG\")   # adjust path if needed\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f8b00a7-e814-4d11-8cd8-192b40e11adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video = pd.read_csv('unicontrol_1080_flow_video.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169b92f0-818d-48a0-a6b0-4116f70144f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PSNR   MS-SSIM     LPIPS       FID           FVD      video  gop  \\\n",
      "0  27.614735  0.914043  0.084901  0.339895  4.593499e+06     Beauty    4   \n",
      "1  23.725834  0.758164  0.168024  1.453007  4.801619e+07     Jockey    4   \n",
      "2  26.111680  0.877629  0.126687  0.565010  2.910645e+06  Bosphorus    4   \n",
      "3  24.298512  0.701864  0.276583  2.291123  9.182728e+06  ShakeNDry    4   \n",
      "4  24.264024  0.863822  0.132418  0.744533  7.155277e+06  YachtRide    4   \n",
      "\n",
      "   flow_storage  intra_bytes  total_storage   total_bits       bpp  \n",
      "0             0    558704.64      558704.64   4469637.12  0.022222  \n",
      "1             0    868577.28      868577.28   6948618.24  0.034546  \n",
      "2             0    961003.52      961003.52   7688028.16  0.038222  \n",
      "3             0   1619957.76     1619957.76  12959662.08  0.064431  \n",
      "4             0   1270179.84     1270179.84  10161438.72  0.050519  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_json_metrics(json_paths, gops):\n",
    "    \"\"\"Load and flatten JSON metric files into a single DataFrame.\"\"\"\n",
    "    all_metrics = []\n",
    "\n",
    "    for path, gop in zip(json_paths, gops):\n",
    "        json_path = Path(path)\n",
    "        if json_path.exists():\n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                for video, metrics in data.items():\n",
    "                    metrics.update(video=video, gop=gop)\n",
    "                    all_metrics.append(metrics)\n",
    "        else:\n",
    "            print(f\"⚠️ JSON not found: {json_path}\")\n",
    "\n",
    "    return pd.DataFrame(all_metrics)\n",
    "\n",
    "\n",
    "def compute_flow_storage(df, grid_id=3):\n",
    "    \"\"\"Add flow_storage (in bytes) per video-gop based on bpp_report.txt.\"\"\"\n",
    "    df[\"flow_storage\"] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        video = row[\"video\"]\n",
    "        gop = row[\"gop\"]\n",
    "        report_path = Path(f\"data/UVG/{video}/1080p/optical_flow_gop_{gop}/grid_{grid_id}/bpp_report.txt\")\n",
    "\n",
    "        total = 0\n",
    "        if report_path.exists():\n",
    "            with open(report_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if ':' in line and 'bytes' in line:\n",
    "                        try:\n",
    "                            size = int(line.split(':')[1].split()[0])\n",
    "                            total += size\n",
    "                        except Exception:\n",
    "                            continue\n",
    "        df.at[idx, \"flow_storage\"] = total\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_intra_storage(csv_path):\n",
    "    \"\"\"Load intra CSV and convert KB to bytes.\"\"\"\n",
    "    df_intra = pd.read_csv(csv_path)\n",
    "    df_intra[\"intra_bytes\"] = df_intra[\"intra_kb\"] * 1024\n",
    "    # Optional: convert 'gop4' → 4\n",
    "    df_intra[\"gop\"] = df_intra[\"gop\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "    return df_intra\n",
    "\n",
    "\n",
    "def merge_and_compute_bpp(df, df_intra, resolution=(1920, 1080), num_frames=97):\n",
    "    \"\"\"Merge with intra storage, then compute total storage, bits, and bpp.\"\"\"\n",
    "    df[\"gop\"] = df[\"gop\"].astype(int)\n",
    "    df_merged = pd.merge(df, df_intra[[\"video\", \"gop\", \"intra_bytes\"]], on=[\"video\", \"gop\"], how=\"left\")\n",
    "\n",
    "    df_merged[\"total_storage\"] = df_merged[\"intra_bytes\"] + df_merged[\"flow_storage\"]\n",
    "    df_merged[\"total_bits\"] = df_merged[\"total_storage\"] * 8\n",
    "\n",
    "    total_pixels = resolution[0] * resolution[1] * num_frames\n",
    "    df_merged[\"bpp\"] = df_merged[\"total_bits\"] / total_pixels\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def main():\n",
    "    json_paths = [\n",
    "        \"./unicontrol_codec_grid9/all_videos_metrics_1080p_q4_4.json\",\n",
    "        \"./unicontrol_codec_grid9/all_videos_metrics_1080p_q4_8.json\",\n",
    "        \"./unicontrol_codec_grid9/all_videos_metrics_1080p_q4_16.json\"\n",
    "    ]\n",
    "    gops = [4, 8, 16]\n",
    "\n",
    "    # Step 1: Load metrics from JSON\n",
    "    df_metrics = load_json_metrics(json_paths, gops)\n",
    "\n",
    "    # Step 2: Compute flow storage from bpp reports\n",
    "    df_metrics = compute_flow_storage(df_metrics, grid_id=3)\n",
    "\n",
    "    # Step 3: Load intra storage\n",
    "    df_intra = load_intra_storage(\"./metrics/intra_uvg.csv\")\n",
    "\n",
    "    # Step 4: Merge and calculate bpp\n",
    "    df_combined = merge_and_compute_bpp(df_metrics, df_intra)\n",
    "\n",
    "    # Show result\n",
    "    print(df_combined.head())\n",
    "\n",
    "    # Optional: save\n",
    "    df_combined.to_csv(\"metrics/Unicontrol_UVG_1080_grid9.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932c66a-0658-4291-bcb8-ccbe4f8a260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
