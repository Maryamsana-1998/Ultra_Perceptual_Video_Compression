{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29bd70f-fefa-485e-936f-ab477630ecc6",
   "metadata": {},
   "source": [
    "# Benchmarking Code and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eae4a96-06d0-4bcd-8cd6-59b585c5b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "# import test_utils\n",
    "#  # replace with actual import if needed\n",
    "# importlib.reload(test_utils)\n",
    "# from test_utils import calculate_metrics_batch \n",
    "\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional,Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8c9ca-6d4c-49ab-97b2-3c06196855d2",
   "metadata": {},
   "source": [
    "## HEVC and H264 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831c7eda-1665-4606-a274-bf6c71b7d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   0%|                                                                                    | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beauty ../data/UVG/Beauty/1080p test_codec/Beauty/h265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Auty CRFs:   0%|                                                                               | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_codec/Beauty/h265/bpp0.01 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos:   0%|                                                                                    | 0/7 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_metrics_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Metrics saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_dir \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28msorted\u001b[39m(BASE_PRED\u001b[38;5;241m.\u001b[39miterdir()), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideos\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m video_dir\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 56\u001b[0m         all_results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mevaluate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASE_ORIG\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Save to file\u001b[39;00m\n\u001b[1;32m     59\u001b[0m parsed_results \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m all_results]\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mevaluate_video\u001b[0;34m(video_dir, orig_base)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(crf_dir, crf_dir\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m crf_dir\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 43\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_crf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrf_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row:\n\u001b[1;32m     45\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m, in \u001b[0;36mevaluate_crf\u001b[0;34m(video, crf_dir, orig_frames)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m---> 20\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics_batch\u001b[49m(orig_frames[:min_len], pred_frames[:min_len])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrf_dir\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS-SSIM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLPIPS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFVD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_metrics_batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Your evaluation function (should be defined elsewhere) ===\n",
    "# def calculate_metrics_batch(orig_images, pred_images) -> Dict[str, float]:\n",
    "#     return {\"PSNR\": ..., \"MS-SSIM\": ..., \"LPIPS\": ..., \"FID\": ..., \"FVD\": ...}\n",
    "\n",
    "# === Config ===\n",
    "BASE_PRED = Path(\"test_codec\")\n",
    "BASE_ORIG = Path(\"../data/UVG\")\n",
    "output_csv = \"metrics_results_h265.csv\"\n",
    "\n",
    "# === Core Functions ===\n",
    "\n",
    "def load_images_from_folder(folder: Path):\n",
    "    return [Image.open(f) for f in sorted(folder.glob(\"*.png\"))]\n",
    "\n",
    "def evaluate_crf(video: str, crf_dir: Path, orig_frames: list):\n",
    "    pred_frames = load_images_from_folder(crf_dir)\n",
    "    min_len = min(len(orig_frames), len(pred_frames))\n",
    "    if min_len == 0:\n",
    "        return []\n",
    "    metrics = calculate_metrics_batch(orig_frames[:min_len], pred_frames[:min_len])\n",
    "    return [\n",
    "        f\"{video},{crf_dir.name},\"\n",
    "        f\"{metrics['PSNR']:.4f},{metrics['MS-SSIM']:.4f},\"\n",
    "        f\"{metrics['LPIPS']:.4f},{metrics['FID']:.4f},{metrics['FVD']:.4f}\"\n",
    "    ]\n",
    "\n",
    "def evaluate_video(video_dir: Path, orig_base: Path):\n",
    "    # print(video_name)\n",
    "    video_name = video_dir.name\n",
    "    crf_root = video_dir / \"h265\"\n",
    "    orig_path = orig_base / video_name / \"1080p\"\n",
    "    print(video_name, orig_path, crf_root )\n",
    "    if not crf_root.is_dir() or not orig_path.is_dir():\n",
    "        return []\n",
    "\n",
    "    orig_frames = load_images_from_folder(orig_path)\n",
    "    results = []\n",
    "\n",
    "    for crf in tqdm(sorted(['bpp0.01', 'bpp0.05','bpp0.1']), desc=f\"{video_name} CRFs\", leave=False):\n",
    "        crf_dir = crf_root / crf \n",
    "        print(crf_dir, crf_dir.is_dir())\n",
    "        if crf_dir.is_dir():\n",
    "            row = evaluate_crf(video_name, crf_dir, orig_frames)\n",
    "            if row:\n",
    "                results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# === Main ===\n",
    "\n",
    "def main():\n",
    "    all_results = []\n",
    "\n",
    "    for video_dir in tqdm(sorted(BASE_PRED.iterdir()), desc=\"Videos\"):\n",
    "        if video_dir.is_dir():\n",
    "            all_results.extend(evaluate_video(video_dir, BASE_ORIG))\n",
    "\n",
    "    # Save to file\n",
    "    parsed_results = [line.split(\",\") for line in all_results]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(parsed_results, columns=[\"Video\", \"CRF\", \"PSNR\", \"MS-SSIM\", \"LPIPS\", \"FID\", \"FVD\"])\n",
    "\n",
    "    # (Optional) Convert numerical columns to float\n",
    "    for col in [\"PSNR\", \"MS-SSIM\", \"LPIPS\", \"FID\", \"FVD\"]:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"\\n✅ Metrics saved to {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690680-d040-4ba4-8a1d-aa0a043f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_bpp(df_grouped: pd.DataFrame, bpp_df: pd.DataFrame, codec_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Attach BPP column to a grouped codec DataFrame based on codec name.\"\"\"\n",
    "    bpp_values = bpp_df.loc[bpp_df['Codec'] == codec_name, 'BPP'].values\n",
    "    df_grouped = df_grouped.copy()\n",
    "    df_grouped['BPP'] = bpp_values\n",
    "    return df_grouped\n",
    "\n",
    "def save_codec_metrics(df_grouped: pd.DataFrame, codec_name: str, out_dir: str = \"benchmark\"):\n",
    "    \"\"\"Save codec metrics with BPP to a CSV file.\"\"\"\n",
    "    filename = f\"{out_dir}/{codec_name}_gop8_benchmarking.csv\"\n",
    "    df_grouped.to_csv(filename, index=False)\n",
    "    print(f\"✅ Saved: {filename}\")\n",
    "\n",
    "# === Usage ===\n",
    "h264_grouped = attach_bpp(h264_grouped, bpp_df, \"h264\")\n",
    "h265_grouped = attach_bpp(h265_grouped, bpp_df, \"h265\")\n",
    "\n",
    "# Save results\n",
    "save_codec_metrics(h264_grouped, \"h264\")\n",
    "save_codec_metrics(h265_grouped, \"h265\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbe149-88bd-427f-939b-4116ee735dc4",
   "metadata": {},
   "source": [
    "## UniControl Bpp Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa3f7e-5114-4ba6-94c4-f1d49496f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- generic helpers --------------------------------------------------\n",
    "KB = 1024.0\n",
    "TOTAL_FRAMES = 97          # change if your dataset differs\n",
    "GOPS          = (4, 8, 16) # gops you care about\n",
    "\n",
    "def read_frame_sizes(report_path: Path) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Return {frame_index: size_kb} from one compression_report.txt.\n",
    "    Accepts either of the two formats you showed.\n",
    "\n",
    "      frame_0000.png → 74.69 KB\n",
    "      - frame_0000.png: 74.69 KB\n",
    "    \"\"\"\n",
    "    if not report_path.is_file():\n",
    "        raise FileNotFoundError(report_path)\n",
    "\n",
    "    pat_arrow = re.compile(r\"frame_(\\d{4})\\.png\\s*→\\s*([\\d.]+)\\s*KB\")\n",
    "    pat_colon = re.compile(r\"frame_(\\d{4})\\.png:\\s*([\\d.]+)\\s*KB\")\n",
    "\n",
    "    sizes = {}\n",
    "    for line in report_path.read_text().splitlines():\n",
    "        m = pat_arrow.search(line) or pat_colon.search(line)\n",
    "        if m:\n",
    "            idx, kb = m.groups()\n",
    "            sizes[int(idx)] = float(kb)\n",
    "    return sizes\n",
    "\n",
    "\n",
    "def intra_storage_kb(frame_sizes: Dict[int, float],\n",
    "                     gop: int,\n",
    "                     total_frames: int = TOTAL_FRAMES) -> float:\n",
    "    \"\"\"Sum sizes of every gop-th frame starting from 0.\"\"\"\n",
    "    return sum(frame_sizes.get(i, 0.0) for i in range(0, total_frames, gop))\n",
    "\n",
    "\n",
    "# ---------- optical-flow helpers ---------------------------------------------\n",
    "def first_bin_size_kb(flow_dir: Path) -> Optional[float]:\n",
    "    \"\"\"Return size (KB) of first .bin inside a folder, or None.\"\"\"\n",
    "    for f in flow_dir.iterdir():\n",
    "        if f.suffix == \".bin\":\n",
    "            return f.stat().st_size / KB\n",
    "    return None\n",
    "\n",
    "\n",
    "def flow_storage_kb(video_1080p: Path, gop: int,\n",
    "                    fallback_size_kb: Optional[float]) -> float:\n",
    "    \"\"\"\n",
    "    Estimate total flow storage as  (#png) × (size of one .bin).\n",
    "\n",
    "    If this GOP has no .bin, uses fallback_size_kb (often GOP-8 size).\n",
    "    \"\"\"\n",
    "    flow_dir = video_1080p / f\"optical_flow_gop_{gop}\"\n",
    "    if not flow_dir.is_dir():\n",
    "        return 0.0\n",
    "\n",
    "    size_kb = first_bin_size_kb(flow_dir) or fallback_size_kb or 0.0\n",
    "    num_png = len([p for p in flow_dir.iterdir() if p.suffix == \".png\"])\n",
    "    return size_kb * num_png\n",
    "\n",
    "\n",
    "# ---------- one-video processing ---------------------------------------------\n",
    "def process_one_video(video_dir: Path,\n",
    "                      decoded_sub = \"decoded_q4\",\n",
    "                      gops       = GOPS) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns a list of rows (one per gop) with keys:\n",
    "      video • gop • intra_kb • flow_kb\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # ---- intra-frame sizes ---------------------------------------------------\n",
    "    report = video_dir / \"1080p\" / decoded_sub / \"compression_report.txt\"\n",
    "    try:\n",
    "        f_sizes = read_frame_sizes(report)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  missing report: {report}\")\n",
    "        return rows\n",
    "\n",
    "    # ---- optical-flow bin fallback (prefer gop-8) ---------------------------\n",
    "    g8_dir = video_dir / \"1080p\" / \"optical_flow_gop_8\"\n",
    "    fallback_kb = first_bin_size_kb(g8_dir)\n",
    "\n",
    "    # ---- per-GOP aggregation -------------------------------------------------\n",
    "    for g in gops:\n",
    "        rows.append(\n",
    "            dict(\n",
    "                video=video_dir.name,\n",
    "                gop=f\"gop{g}\",\n",
    "                intra_kb=intra_storage_kb(f_sizes, g),\n",
    "                flow_kb=flow_storage_kb(video_dir / \"1080p\", g, fallback_kb),\n",
    "            )\n",
    "        )\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ---------- dataset-wide driver ----------------------------------------------\n",
    "def build_storage_dataframe(base_dir: Union[str, Path],\n",
    "                            decoded_sub = \"decoded_q4\",\n",
    "                            gops       = GOPS) -> pd.DataFrame:\n",
    "    records = []\n",
    "    base = Path(base_dir)\n",
    "    for video_dir in sorted(base.iterdir()):\n",
    "        if video_dir.is_dir():\n",
    "            records.extend(process_one_video(video_dir,\n",
    "                                             decoded_sub=decoded_sub,\n",
    "                                             gops=gops))\n",
    "    df = pd.DataFrame(records)\n",
    "    # Optional pivot to wide format (one row per video)\n",
    "    #   df = df.pivot(index=\"video\", columns=\"gop\", values=[\"intra_kb\",\"flow_kb\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------- run ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = build_storage_dataframe(\"../data/UVG\")   # adjust path if needed\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66598374-4f5d-4db6-912e-ff3983539d98",
   "metadata": {},
   "source": [
    "## UniControl Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b92f0-818d-48a0-a6b0-4116f70144f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_json_metrics(json_paths, gops):\n",
    "    \"\"\"Load and flatten JSON metric files into a single DataFrame.\"\"\"\n",
    "    all_metrics = []\n",
    "\n",
    "    for path, gop in zip(json_paths, gops):\n",
    "        json_path = Path(path)\n",
    "        if json_path.exists():\n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                for video, metrics in data.items():\n",
    "                    metrics.update(video=video, gop=gop)\n",
    "                    all_metrics.append(metrics)\n",
    "        else:\n",
    "            print(f\"⚠️ JSON not found: {json_path}\")\n",
    "\n",
    "    return pd.DataFrame(all_metrics)\n",
    "\n",
    "\n",
    "def compute_flow_storage(df, grid_id=3):\n",
    "    \"\"\"Add flow_storage (in bytes) per video-gop based on bpp_report.txt.\"\"\"\n",
    "    df[\"flow_storage\"] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        video = row[\"video\"]\n",
    "        gop = row[\"gop\"]\n",
    "        report_path = Path(f\"../data/UVG/{video}/1080p/optical_flow_gop_{gop}/grid_{grid_id}/bpp_report.txt\")\n",
    "        print(report_path, report_path.exists())\n",
    "        total = 0\n",
    "        if report_path.exists():\n",
    "            with open(report_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if ':' in line and 'bytes' in line:\n",
    "                        try:\n",
    "                            size = int(line.split(':')[1].split()[0])\n",
    "                            total += size\n",
    "                        except Exception:\n",
    "                            continue\n",
    "        df.at[idx, \"flow_storage\"] = total\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_intra_storage(csv_path):\n",
    "    \"\"\"Load intra CSV and convert KB to bytes.\"\"\"\n",
    "    df_intra = pd.read_csv(csv_path)\n",
    "    df_intra[\"intra_bytes\"] = df_intra[\"intra_kb\"] * 1024\n",
    "    # Optional: convert 'gop4' → 4\n",
    "    df_intra[\"gop\"] = df_intra[\"gop\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "    return df_intra\n",
    "\n",
    "\n",
    "def merge_and_compute_bpp(df, df_intra, resolution=(1920, 1080), num_frames=97):\n",
    "    \"\"\"Merge with intra storage, then compute total storage, bits, and bpp.\"\"\"\n",
    "    df[\"gop\"] = df[\"gop\"].astype(int)\n",
    "    df_merged = pd.merge(df, df_intra[[\"video\", \"gop\", \"intra_bytes\"]], on=[\"video\", \"gop\"], how=\"left\")\n",
    "\n",
    "    df_merged[\"total_storage\"] = df_merged[\"intra_bytes\"] + df_merged[\"flow_storage\"]\n",
    "    df_merged[\"total_bits\"] = df_merged[\"total_storage\"] * 8\n",
    "\n",
    "    total_pixels = resolution[0] * resolution[1] * num_frames\n",
    "    df_merged[\"bpp\"] = df_merged[\"total_bits\"] / total_pixels\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def main():\n",
    "    json_paths = [\n",
    "        \"./unicontrol_codec_grid15/all_videos_metrics_1080p_q4_4.json\",\n",
    "        \"./unicontrol_codec_grid15/all_videos_metrics_1080p_q4_8.json\",\n",
    "        \"./unicontrol_codec_grid15/all_videos_metrics_1080p_q4_16.json\"\n",
    "    ]\n",
    "    gops = [4, 8, 16]\n",
    "\n",
    "    # Step 1: Load metrics from JSON\n",
    "    df_metrics = load_json_metrics(json_paths, gops)\n",
    "\n",
    "    # Step 2: Compute flow storage from bpp reports\n",
    "    df_metrics = compute_flow_storage(df_metrics, grid_id=15)\n",
    "\n",
    "    # Step 3: Load intra storage\n",
    "    df_intra = load_intra_storage(\"./metrics/intra_uvg.csv\")\n",
    "\n",
    "    # Step 4: Merge and calculate bpp\n",
    "    df_combined = merge_and_compute_bpp(df_metrics, df_intra)\n",
    "\n",
    "    # Show result\n",
    "    print(df_combined.head())\n",
    "\n",
    "    # Optional: save\n",
    "    df_combined.to_csv(\"metrics/Unicontrol_UVG_1080_grid15.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932c66a-0658-4291-bcb8-ccbe4f8a260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
